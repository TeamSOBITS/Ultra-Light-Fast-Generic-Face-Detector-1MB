<!-- ulfg_face_detector/face_detect_with_tf.launch -->

<launch>

    <group ns = "ulfg_face_detect">

        <param name="ulfg_img_show_flag" type="bool" value="true"/>                 <!--  -->
        <param name="ulfg_execute_default" type="bool" value="true"/>               <!--  -->
        <param name="ulfg_pub_result_image" type="bool" value="true"/>              <!--  -->
        <param name="needs_time_stamp" type="bool" value="true"/>                   <!-- publish boundingboxes with time stamp -->
        <param name="unique_class_flag" type="bool" value="false"/>                 <!-- face or face_0, 1, 2,... -->

        <param name="ulfg_image_topic_name" type="str" value="/rgb/image_raw"/>     <!--Azurekinect >> /rgb/image_raw , xion >> /camera/rgb/image_raw -->
        <param name="ulfg_cloud_topic_name" type="str" value="/points2"/>           <!--Azurekinect >> /points2 , xion >> /camera/depth_registered/points -->
        <param name="ulfg_target_frame_name" type="str" value="/camera_base"/>   <!-- use with robot >> /base_footprint, only Azure Kinect >> /camera_base , only xion >> /camera_rgb_optical_frame -->
        <param name="ulfg_camera_width_size" type="int" value="1280"/>              <!--define network input size,default optional value 128/160/320/480/640/1280 -->

        <param name="net_type" type="str" value="mb_tiny_RFB_fd"/>                  <!--The network architecture ,optional:1. mb_tiny_RFB_fd (higher precision) or 2.mb_tiny_fd (faster)-->
        <param name="test_device" type="str" value="cpu"/>                          <!--cpu or cuda:0-->
        <param name="ulfg_inScaleFactor" type="double" value="1.0"/>                <!-- image magnification ratio -->
        <param name="ulfg_confidenceThreshold" type="double" value="0.8"/>          <!-- Detct face threshold -->
        <param name="ulfg_candidate_size" type="int" value="1000"/>                 <!-- Max size of detct face number -->
        
        <param name="ulfg_path" type="str" value="$(find ulfg_face_detector)/"/>
        <param name="ulfg_label_file_path" type="str" value="$(find ulfg_face_detector)/models/voc-model-labels.txt"/>

        <param name="ulfg_prototxt_name" type="str" value="face.prototxt"/>
        <param name="ulfg_caffemodel_name" type="str" value="face.caffemodel"/>


        <node pkg="ulfg_face_detector" type="face_detect_ros.py" name="face_detect_ros" output="screen"/>
        <node pkg="ulfg_face_detector" type="ulfg_tf_broadcaster" name="ulfg_tf_broadcaster" output="screen"/>
    </group>

</launch>
